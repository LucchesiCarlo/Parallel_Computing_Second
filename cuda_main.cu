//
// Created by giacomo on 1/19/26.
//

#include <iostream>
#include <string>
#include <filesystem>
#include <fstream>
namespace fs = std::filesystem;

#include "opencv2/core.hpp"
#include <opencv2/core/mat.hpp>
#include <opencv2/imgcodecs.hpp>
#include <cuda_runtime.h>
#include <cuda_runtime_api.h>
#include "src/kernel_functions.h"
#include "src/cuda_kernel.cuh"

//Generated by Gemini pro to handle CUDA errors
#define CUDA_CHECK(call) \
do { \
    cudaError_t err = call; \
    if (err != cudaSuccess) { \
        fprintf(stderr, "CUDA error at %s:%d code=%d(%s) \n", \
        __FILE__, __LINE__, err, cudaGetErrorString(err)); \
        exit(EXIT_FAILURE); \
    } \
} while (0)


#define MAX_W 150
#define MAX_H 150
#define K 3
#define C 3

int main() {

    auto start_e2e = std::chrono::high_resolution_clock::now();

    float kernel[K*K];
    generateKernel(kernel, Gaussian);

    loadKernel(kernel, K);

    unsigned char * deviceInput;
    unsigned char * deviceOutput;

    cudaMalloc(&deviceInput, MAX_W*MAX_H*sizeof(unsigned char)*C);
    cudaMalloc(&deviceOutput, MAX_W*MAX_H*sizeof(unsigned char)*C);

    //we choose blocks 32x4. So, to cover all the images 150*150 we need a grid 5x38
    dim3 dimGrid(5,38);
    dim3 dimBlock(32,4);

    std::string path = "../dataset/seg_pred/seg_pred";
    int count = 0;

    double total_k = 0;
    for (const auto & entry : fs::directory_iterator(path)) {
        cv::Mat inputImg = cv::imread(entry.path(), cv::IMREAD_UNCHANGED);
        cv::Size size = inputImg.size();

        //Access raw bytes of the image
        auto inputPtr = inputImg.ptr();


        cudaMemcpy(deviceInput, inputPtr, sizeof(unsigned char)*size.height*size.width*inputImg.channels(), cudaMemcpyKind::cudaMemcpyHostToDevice);

        cv::Mat outputImg = cv::Mat::zeros(inputImg.size(), inputImg.type());

        auto outputPtr = outputImg.ptr();

        if (inputImg.empty()) {
            continue;
        }

        auto start_k = std::chrono::high_resolution_clock::now();

        int dimTile = (dimBlock.x + (K-1))*(dimBlock.y + (K-1))*C;

        // the third parameter in <<< >>> is ignored if the shared memory is not allocated
        applyCudaKernel <<<dimGrid, dimBlock, dimTile>>> (deviceInput, deviceOutput, K, size.width, size.height, inputImg.channels());
        cudaDeviceSynchronize();
        auto end_k = std::chrono::high_resolution_clock::now();
        total_k += std::chrono::duration_cast<std::chrono::duration<double>>(end_k - start_k).count();
        count++;

        cudaMemcpy(outputPtr, deviceOutput, sizeof(unsigned char)*size.height*size.width*inputImg.channels(), cudaMemcpyKind::cudaMemcpyDeviceToHost);

        std::string outputPath = "../cuda_tiling_output/" + entry.path().filename().string();
        cv::imwrite(outputPath, outputImg);

    }

    cudaFree(deviceInput);
    cudaFree(deviceOutput);

    auto end_e2e = std::chrono::high_resolution_clock::now();
    auto time_e2e = std::chrono::duration_cast<std::chrono::duration<double>>(end_e2e - start_e2e).count();


    std::cout << "Time Taken End to End:" << time_e2e << "s" << std::endl;
    std::cout << "Time Taken to apply kernel:" << total_k/count << "s" << std::endl;
    std::cout << "Elements Elaborated:" << count << std::endl;

}
